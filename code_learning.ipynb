{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.relu(self.linear2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.relu(self.linear2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(torch.nn.Module):\n",
    "    latent_dim = 8  # 隐变量维度\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # 编码器到均值和log方差的两个网络, 且默认知道编码器的最后一层维度为100, 隐变量维度为8\n",
    "        self._enc_mu = torch.nn.Linear(100, 8)\n",
    "        self._enc_log_sigma = torch.nn.Linear(100, 8)\n",
    "\n",
    "    def _sample_latent(self, h_enc):\n",
    "        \"\"\"\n",
    "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
    "        \"\"\"\n",
    "        mu = self._enc_mu(h_enc)\n",
    "        log_sigma = self._enc_log_sigma(h_enc)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
    "\n",
    "        self.z_mean = mu\n",
    "        self.z_sigma = sigma\n",
    "\n",
    "        return mu + sigma * std_z  # Reparameterization trick\n",
    "    \n",
    "    \n",
    "    def forward(self, state):\n",
    "        h_enc = self.encoder(state)  # 编码器的输出\n",
    "        z = self._sample_latent(h_enc)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算KL散度误差项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算KL散度误差项\n",
    "def latent_loss(z_mean, z_stddev):\n",
    "    mean_sq = z_mean * z_mean\n",
    "    stddev_sq = z_stddev * z_stddev\n",
    "    return 0.5 * torch.mean(mean_sq + stddev_sq - torch.log(stddev_sq) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  60000\n",
      "0 0.07134895771741867\n",
      "1 0.06250201910734177\n",
      "2 0.07147786021232605\n",
      "3 0.06432824581861496\n",
      "4 0.06242973357439041\n",
      "5 0.06560368835926056\n",
      "6 0.06614285707473755\n",
      "7 0.07027167081832886\n",
      "8 0.06962623447179794\n",
      "9 0.0656011551618576\n",
      "10 0.06550559401512146\n",
      "11 0.06820596009492874\n",
      "12 0.06393261253833771\n",
      "13 0.06882257014513016\n",
      "14 0.06708746403455734\n",
      "15 0.0640035942196846\n",
      "16 0.06641925126314163\n",
      "17 0.06491492688655853\n",
      "18 0.06631259620189667\n",
      "19 0.06409668177366257\n",
      "20 0.07062452286481857\n",
      "21 0.06658756732940674\n",
      "22 0.06735407561063766\n",
      "23 0.06352271884679794\n",
      "24 0.06419023126363754\n",
      "25 0.0674062967300415\n",
      "26 0.06671597808599472\n",
      "27 0.07069134712219238\n",
      "28 0.07186707109212875\n",
      "29 0.0706745907664299\n",
      "30 0.06385093927383423\n",
      "31 0.061521705240011215\n",
      "32 0.06785331666469574\n",
      "33 0.0714964047074318\n",
      "34 0.06357137858867645\n",
      "35 0.06244207173585892\n",
      "36 0.06802600622177124\n",
      "37 0.06563977152109146\n",
      "38 0.06497756391763687\n",
      "39 0.0698019489645958\n",
      "40 0.07012210786342621\n",
      "41 0.066471166908741\n",
      "42 0.07034033536911011\n",
      "43 0.06604138016700745\n",
      "44 0.06402270495891571\n",
      "45 0.06867346912622452\n",
      "46 0.06646992266178131\n",
      "47 0.06477990746498108\n",
      "48 0.07063048332929611\n",
      "49 0.06826095283031464\n",
      "50 0.06957997381687164\n",
      "51 0.07156520336866379\n",
      "52 0.0650445893406868\n",
      "53 0.0690910592675209\n",
      "54 0.06824556738138199\n",
      "55 0.06914100795984268\n",
      "56 0.07754664123058319\n",
      "57 0.0647226944565773\n",
      "58 0.06479286402463913\n",
      "59 0.0639842078089714\n",
      "60 0.06603508442640305\n",
      "61 0.06959298998117447\n",
      "62 0.06828182190656662\n",
      "63 0.0642179325222969\n",
      "64 0.07253146171569824\n",
      "65 0.06380515545606613\n",
      "66 0.06857497990131378\n",
      "67 0.06819608062505722\n",
      "68 0.06656869500875473\n",
      "69 0.07603681832551956\n",
      "70 0.06628483533859253\n",
      "71 0.06899062544107437\n",
      "72 0.06732103228569031\n",
      "73 0.06473647803068161\n",
      "74 0.07553360611200333\n",
      "75 0.06662404537200928\n",
      "76 0.06926976889371872\n",
      "77 0.07061533629894257\n",
      "78 0.06734685599803925\n",
      "79 0.06583286076784134\n",
      "80 0.07474885135889053\n",
      "81 0.06906700134277344\n",
      "82 0.06602159887552261\n",
      "83 0.0664067417383194\n",
      "84 0.06426886469125748\n",
      "85 0.06555956602096558\n",
      "86 0.0684279277920723\n",
      "87 0.0689331516623497\n",
      "88 0.06752655655145645\n",
      "89 0.06259027123451233\n",
      "90 0.0638972669839859\n",
      "91 0.06466373056173325\n",
      "92 0.06821434199810028\n",
      "93 0.06641510874032974\n",
      "94 0.06567498296499252\n",
      "95 0.0678633376955986\n",
      "96 0.06940081715583801\n",
      "97 0.06944236159324646\n",
      "98 0.0682387501001358\n",
      "99 0.06619413942098618\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim = 28 * 28\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "mnist = torchvision.datasets.MNIST('./', download=True, transform=transform)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(mnist, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "print('Number of samples: ', len(mnist))\n",
    "\n",
    "encoder = Encoder(input_dim, 100, 100)  # 隐藏层维度为100, 输出维度为100\n",
    "decoder = Decoder(8, 100, input_dim)  # 隐藏层维度为100\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.0001)\n",
    "l = None\n",
    "for epoch in range(100):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, classes = data\n",
    "        inputs.resize_(batch_size, input_dim)\n",
    "        optimizer.zero_grad()\n",
    "        dec = vae(inputs)  # 获得的输出端解码\n",
    "        ll = latent_loss(vae.z_mean, vae.z_sigma)\n",
    "        loss = criterion(dec, inputs) + ll  # 重建误差 + KL散度误差\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l = loss.item()\n",
    "        # l = loss.data[0]\n",
    "        \"\"\"\n",
    "        考虑在 PyTorch0.4.0 版本之前广泛使用的 total_loss + = loss.data [0] 模式\n",
    "        Loss 是一个包含张量(1, )的Variable, 但是在新发布的 0.4.0 版本中. loss 是一个0维标量, 对于标量的索引是没有意义的\n",
    "        使用 loss.item（）从标量中获取 Python 数字\n",
    "        \"\"\"\n",
    "    print(epoch, l)\n",
    "\n",
    "plt.imshow(vae(inputs).data[0].numpy().reshape(28, 28), cmap='gray')\n",
    "plt.show(block=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
